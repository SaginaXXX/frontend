import{c as A,g as oe}from"./main-gcnKPqYr.js";import{a as J}from"./ort-web.min-OS_AKbTQ.js";function ne(e,n){for(var o=0;o<n.length;o++){const t=n[o];if(typeof t!="string"&&!Array.isArray(t)){for(const s in t)if(s!=="default"&&!(s in e)){const r=Object.getOwnPropertyDescriptor(t,s);r&&Object.defineProperty(e,s,r.get?r:{enumerable:!0,get:()=>t[s]})}}}return Object.freeze(Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}))}var W={},L={};Object.defineProperty(L,"__esModule",{value:!0});L.baseAssetPath=void 0;const ie=typeof window<"u"&&typeof window.document<"u",G=ie?window.document.currentScript:null;let K="/";G&&(K=G.src.replace(/#.*$/,"").replace(/\?.*$/,"").replace(/\/[^\/]+$/,"/"));L.baseAssetPath=K;var N={};Object.defineProperty(N,"__esModule",{value:!0});N.defaultModelFetcher=void 0;const ae=e=>fetch(e).then(n=>n.arrayBuffer());N.defaultModelFetcher=ae;var w={},T={};(function(e){Object.defineProperty(e,"__esModule",{value:!0}),e.log=e.LOG_PREFIX=void 0,e.LOG_PREFIX="[VAD]";const n=["error","debug","warn"];function o(s){return(...r)=>{console[s](e.LOG_PREFIX,...r)}}const t=n.reduce((s,r)=>(s[r]=o(r),s),{});e.log=t})(T);var M={};Object.defineProperty(M,"__esModule",{value:!0});M.Message=void 0;var H;(function(e){e.AudioFrame="AUDIO_FRAME",e.SpeechStart="SPEECH_START",e.VADMisfire="VAD_MISFIRE",e.SpeechEnd="SPEECH_END",e.SpeechStop="SPEECH_STOP"})(H||(M.Message=H={}));Object.defineProperty(w,"__esModule",{value:!0});w.FrameProcessor=w.validateOptions=w.defaultV5FrameProcessorOptions=w.defaultLegacyFrameProcessorOptions=void 0;const R=T,E=M,ce=[512,1024,1536];w.defaultLegacyFrameProcessorOptions={positiveSpeechThreshold:.5,negativeSpeechThreshold:.5-.15,preSpeechPadFrames:1,redemptionFrames:8,frameSamples:1536,minSpeechFrames:3,submitUserSpeechOnPause:!1};w.defaultV5FrameProcessorOptions={positiveSpeechThreshold:.5,negativeSpeechThreshold:.5-.15,preSpeechPadFrames:3,redemptionFrames:24,frameSamples:512,minSpeechFrames:9,submitUserSpeechOnPause:!1};function ue(e){ce.includes(e.frameSamples)||R.log.warn("You are using an unusual frame size"),(e.positiveSpeechThreshold<0||e.positiveSpeechThreshold>1)&&R.log.error("positiveSpeechThreshold should be a number between 0 and 1"),(e.negativeSpeechThreshold<0||e.negativeSpeechThreshold>e.positiveSpeechThreshold)&&R.log.error("negativeSpeechThreshold should be between 0 and positiveSpeechThreshold"),e.preSpeechPadFrames<0&&R.log.error("preSpeechPadFrames should be positive"),e.redemptionFrames<0&&R.log.error("redemptionFrames should be positive")}w.validateOptions=ue;const X=e=>{const n=e.reduce((t,s)=>(t.push(t.at(-1)+s.length),t),[0]),o=new Float32Array(n.at(-1));return e.forEach((t,s)=>{const r=n[s];o.set(t,r)}),o};class le{constructor(n,o,t){this.modelProcessFunc=n,this.modelResetFunc=o,this.options=t,this.speaking=!1,this.redemptionCounter=0,this.active=!1,this.reset=()=>{this.speaking=!1,this.audioBuffer=[],this.modelResetFunc(),this.redemptionCounter=0},this.pause=()=>(this.active=!1,this.options.submitUserSpeechOnPause?this.endSegment():(this.reset(),{})),this.resume=()=>{this.active=!0},this.endSegment=()=>{const s=this.audioBuffer;this.audioBuffer=[];const r=this.speaking;this.reset();const a=s.reduce((c,i)=>c+ +i.isSpeech,0);if(r)if(a>=this.options.minSpeechFrames){const c=X(s.map(i=>i.frame));return{msg:E.Message.SpeechEnd,audio:c}}else return{msg:E.Message.VADMisfire};return{}},this.process=async s=>{if(!this.active)return{};const r=await this.modelProcessFunc(s);if(this.audioBuffer.push({frame:s,isSpeech:r.isSpeech>=this.options.positiveSpeechThreshold}),r.isSpeech>=this.options.positiveSpeechThreshold&&this.redemptionCounter&&(this.redemptionCounter=0),r.isSpeech>=this.options.positiveSpeechThreshold&&!this.speaking)return this.speaking=!0,{probs:r,msg:E.Message.SpeechStart,frame:s};if(r.isSpeech<this.options.negativeSpeechThreshold&&this.speaking&&++this.redemptionCounter>=this.options.redemptionFrames){this.redemptionCounter=0,this.speaking=!1;const a=this.audioBuffer;if(this.audioBuffer=[],a.reduce((i,d)=>i+ +d.isSpeech,0)>=this.options.minSpeechFrames){const i=X(a.map(d=>d.frame));return{probs:r,msg:E.Message.SpeechEnd,audio:i,frame:s}}else return{probs:r,msg:E.Message.VADMisfire,frame:s}}if(!this.speaking)for(;this.audioBuffer.length>this.options.preSpeechPadFrames;)this.audioBuffer.shift();return{probs:r,frame:s}},this.audioBuffer=[],this.reset()}}w.FrameProcessor=le;var Q={},I={},Z={};Object.defineProperty(Z,"__esModule",{value:!0});var C={},x;Object.defineProperty(C,"__esModule",{value:!0});C.SileroLegacy=void 0;const Y=T;class z{constructor(n,o,t,s,r){this.ortInstance=n,this._session=o,this._h=t,this._c=s,this._sr=r,this.reset_state=()=>{const a=Array(128).fill(0);this._h=new this.ortInstance.Tensor("float32",a,[2,1,64]),this._c=new this.ortInstance.Tensor("float32",a,[2,1,64])},this.process=async a=>{const i={input:new this.ortInstance.Tensor("float32",a,[1,a.length]),h:this._h,c:this._c,sr:this._sr},d=await this._session.run(i);this._h=d.hn,this._c=d.cn;const[m]=d.output?.data;return{notSpeech:1-m,isSpeech:m}}}}C.SileroLegacy=z;x=z;z.new=async(e,n)=>{Y.log.debug("initializing vad");const o=await n(),t=await e.InferenceSession.create(o),s=new e.Tensor("int64",[16000n]),r=Array(2*64).fill(0),a=new e.Tensor("float32",r,[2,1,64]),c=new e.Tensor("float32",r,[2,1,64]);return Y.log.debug("vad is initialized"),new x(e,t,a,c,s)};var U={},ee;Object.defineProperty(U,"__esModule",{value:!0});U.SileroV5=void 0;const q=T;function te(e){const n=Array(256).fill(0);return new e.Tensor("float32",n,[2,1,128])}class ${constructor(n,o,t,s){this._session=n,this._state=o,this._sr=t,this.ortInstance=s,this.reset_state=()=>{this._state=te(this.ortInstance)},this.process=async r=>{const c={input:new this.ortInstance.Tensor("float32",r,[1,r.length]),state:this._state,sr:this._sr},i=await this._session.run(c);this._state=i.stateN;const[d]=i.output?.data;return{notSpeech:1-d,isSpeech:d}}}}U.SileroV5=$;ee=$;$.new=async(e,n)=>{q.log.debug("Loading VAD...");const o=await n(),t=await e.InferenceSession.create(o),s=new e.Tensor("int64",[16000n]),r=te(e);return q.log.debug("...finished loading VAD"),new ee(t,r,s,e)};(function(e){var n=A&&A.__createBinding||(Object.create?function(r,a,c,i){i===void 0&&(i=c);var d=Object.getOwnPropertyDescriptor(a,c);(!d||("get"in d?!a.__esModule:d.writable||d.configurable))&&(d={enumerable:!0,get:function(){return a[c]}}),Object.defineProperty(r,i,d)}:function(r,a,c,i){i===void 0&&(i=c),r[i]=a[c]}),o=A&&A.__exportStar||function(r,a){for(var c in r)c!=="default"&&!Object.prototype.hasOwnProperty.call(a,c)&&n(a,r,c)};Object.defineProperty(e,"__esModule",{value:!0}),e.SileroV5=e.SileroLegacy=void 0,o(Z,e);var t=C;Object.defineProperty(e,"SileroLegacy",{enumerable:!0,get:function(){return t.SileroLegacy}});var s=U;Object.defineProperty(e,"SileroV5",{enumerable:!0,get:function(){return s.SileroV5}})})(I);var B={};Object.defineProperty(B,"__esModule",{value:!0});B.Resampler=void 0;const de=T;class he{constructor(n){this.options=n,this.process=o=>{const t=[];for(const s of o)for(this.inputBuffer.push(s);this.hasEnoughDataForFrame();){const r=this.generateOutputFrame();t.push(r)}return t},this.stream=async function*(o){for(const t of o)for(this.inputBuffer.push(t);this.hasEnoughDataForFrame();)yield this.generateOutputFrame()},n.nativeSampleRate<16e3&&de.log.error("nativeSampleRate is too low. Should have 16000 = targetSampleRate <= nativeSampleRate"),this.inputBuffer=[]}hasEnoughDataForFrame(){return this.inputBuffer.length*this.options.targetSampleRate/this.options.nativeSampleRate>=this.options.targetFrameSize}generateOutputFrame(){const n=new Float32Array(this.options.targetFrameSize);let o=0,t=0;for(;o<this.options.targetFrameSize;){let s=0,r=0;for(;t<Math.min(this.inputBuffer.length,(o+1)*this.options.nativeSampleRate/this.options.targetSampleRate);){const a=this.inputBuffer[t];a!==void 0&&(s+=a,r++),t++}n[o]=s/r,o++}return this.inputBuffer=this.inputBuffer.slice(t),n}}B.Resampler=he;(function(e){Object.defineProperty(e,"__esModule",{value:!0}),e.PlatformAgnosticNonRealTimeVAD=e.defaultNonRealTimeVADOptions=void 0;const n=w,o=M,t=I,s=B;e.defaultNonRealTimeVADOptions={...n.defaultLegacyFrameProcessorOptions,ortConfig:void 0};class r{static async _new(c,i,d={}){const m={...e.defaultNonRealTimeVADOptions,...d};m.ortConfig!==void 0&&m.ortConfig(i);const O=new this(c,i,m);return await O.init(),O}constructor(c,i,d){this.modelFetcher=c,this.ort=i,this.options=d,this.init=async()=>{const m=await t.SileroLegacy.new(this.ort,this.modelFetcher);this.frameProcessor=new n.FrameProcessor(m.process,m.reset_state,{frameSamples:this.options.frameSamples,positiveSpeechThreshold:this.options.positiveSpeechThreshold,negativeSpeechThreshold:this.options.negativeSpeechThreshold,redemptionFrames:this.options.redemptionFrames,preSpeechPadFrames:this.options.preSpeechPadFrames,minSpeechFrames:this.options.minSpeechFrames,submitUserSpeechOnPause:this.options.submitUserSpeechOnPause}),this.frameProcessor.resume()},this.run=async function*(m,O){const D={nativeSampleRate:O,targetSampleRate:16e3,targetFrameSize:this.options.frameSamples},S=new s.Resampler(D);let g=0,_=0,v=0;for await(const h of S.stream(m)){const{msg:u,audio:l}=await this.frameProcessor.process(h);switch(u){case o.Message.SpeechStart:g=v*this.options.frameSamples/16;break;case o.Message.SpeechEnd:_=(v+1)*this.options.frameSamples/16,yield{audio:l,start:g,end:_};break}v++}const{msg:f,audio:p}=this.frameProcessor.endSegment();f==o.Message.SpeechEnd&&(yield{audio:p,start:g,end:v*this.options.frameSamples/16})},(0,n.validateOptions)(d)}}e.PlatformAgnosticNonRealTimeVAD=r})(Q);var P={};Object.defineProperty(P,"__esModule",{value:!0});P.audioFileToArray=P.encodeWAV=P.arrayBufferToBase64=P.minFramesForTargetMS=void 0;function fe(e,n,o=16e3){return Math.ceil(e*o/1e3/n)}P.minFramesForTargetMS=fe;function pe(e){const n=new Uint8Array(e),o=n.byteLength,t=new Array(o);for(var s=0;s<o;s++){const r=n[s];if(r===void 0)break;t[s]=String.fromCharCode(r)}return btoa(t.join(""))}P.arrayBufferToBase64=pe;function me(e,n=3,o=16e3,t=1,s=32){var r=s/8,a=t*r,c=new ArrayBuffer(44+e.length*r),i=new DataView(c);return j(i,0,"RIFF"),i.setUint32(4,36+e.length*r,!0),j(i,8,"WAVE"),j(i,12,"fmt "),i.setUint32(16,16,!0),i.setUint16(20,n,!0),i.setUint16(22,t,!0),i.setUint32(24,o,!0),i.setUint32(28,o*a,!0),i.setUint16(32,a,!0),i.setUint16(34,s,!0),j(i,36,"data"),i.setUint32(40,e.length*r,!0),n===1?Se(i,44,e):ge(i,44,e),c}P.encodeWAV=me;function ge(e,n,o){for(var t=0;t<o.length;t++,n+=4)e.setFloat32(n,o[t],!0)}function Se(e,n,o){for(var t=0;t<o.length;t++,n+=2){var s=Math.max(-1,Math.min(1,o[t]));e.setInt16(n,s<0?s*32768:s*32767,!0)}}function j(e,n,o){for(var t=0;t<o.length;t++)e.setUint8(n+t,o.charCodeAt(t))}async function _e(e){const n=new OfflineAudioContext(1,1,44100),o=new FileReader;let t=null;if(await new Promise(a=>{o.addEventListener("loadend",c=>{const i=o.result;n.decodeAudioData(i,d=>{t=d,n.startRendering().then(m=>{console.log("Rendering completed successfully"),a()}).catch(m=>{console.error(`Rendering failed: ${m}`)})},d=>{console.log(`Error with decoding audio data: ${d}`)})}),o.readAsArrayBuffer(e)}),t===null)throw Error("some shit");let s=t,r=new Float32Array(s.length);for(let a=0;a<s.length;a++)for(let c=0;c<s.numberOfChannels;c++)r[a]+=s.getChannelData(c)[a];return{audio:r,sampleRate:s.sampleRate}}P.audioFileToArray=_e;var se={};(function(e){var n=A&&A.__createBinding||(Object.create?function(f,p,h,u){u===void 0&&(u=h);var l=Object.getOwnPropertyDescriptor(p,h);(!l||("get"in l?!p.__esModule:l.writable||l.configurable))&&(l={enumerable:!0,get:function(){return p[h]}}),Object.defineProperty(f,u,l)}:function(f,p,h,u){u===void 0&&(u=h),f[u]=p[h]}),o=A&&A.__setModuleDefault||(Object.create?function(f,p){Object.defineProperty(f,"default",{enumerable:!0,value:p})}:function(f,p){f.default=p}),t=A&&A.__importStar||function(f){if(f&&f.__esModule)return f;var p={};if(f!=null)for(var h in f)h!=="default"&&Object.prototype.hasOwnProperty.call(f,h)&&n(p,f,h);return o(p,f),p};Object.defineProperty(e,"__esModule",{value:!0}),e.AudioNodeVAD=e.MicVAD=e.getDefaultRealTimeVADOptions=e.ort=e.DEFAULT_MODEL=void 0;const s=t(J),r=N,a=w,c=T,i=M,d=I,m=B;e.DEFAULT_MODEL="legacy",e.ort=s;const O="vad.worklet.bundle.min.js",D="silero_vad_v5.onnx",S="silero_vad_legacy.onnx",g=f=>({...f==="v5"?a.defaultV5FrameProcessorOptions:a.defaultLegacyFrameProcessorOptions,onFrameProcessed:h=>{},onVADMisfire:()=>{c.log.debug("VAD misfire")},onSpeechStart:()=>{c.log.debug("Detected speech start")},onSpeechEnd:()=>{c.log.debug("Detected speech end")},baseAssetPath:"https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/",onnxWASMBasePath:"https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/",stream:void 0,ortConfig:void 0,model:e.DEFAULT_MODEL,workletOptions:{}});e.getDefaultRealTimeVADOptions=g;class _{static async new(p={}){const h={...(0,e.getDefaultRealTimeVADOptions)(p.model??e.DEFAULT_MODEL),...p};(0,a.validateOptions)(h);let u;h.stream===void 0?u=await navigator.mediaDevices.getUserMedia({audio:{...h.additionalAudioConstraints,channelCount:1,echoCancellation:!0,autoGainControl:!0,noiseSuppression:!0}}):u=h.stream;const l=new AudioContext,y=new MediaStreamAudioSourceNode(l,{mediaStream:u}),F=await v.new(l,h);return F.receive(y),new _(h,l,u,F,y)}constructor(p,h,u,l,y,F=!1){this.options=p,this.audioContext=h,this.stream=u,this.audioNodeVAD=l,this.sourceNode=y,this.listening=F,this.pause=()=>{this.audioNodeVAD.pause(),this.listening=!1},this.start=()=>{this.audioNodeVAD.start(),this.listening=!0},this.destroy=()=>{this.listening&&this.pause(),this.options.stream===void 0&&this.stream.getTracks().forEach(b=>b.stop()),this.sourceNode.disconnect(),this.audioNodeVAD.destroy(),this.audioContext.close()}}}e.MicVAD=_;class v{static async new(p,h={}){const u={...(0,e.getDefaultRealTimeVADOptions)(h.model??e.DEFAULT_MODEL),...h};(0,a.validateOptions)(u),e.ort.env.wasm.wasmPaths=u.onnxWASMBasePath,u.ortConfig!==void 0&&u.ortConfig(e.ort);const l=u.model==="v5"?D:S,y=u.baseAssetPath+l,F=u.model==="v5"?d.SileroV5.new:d.SileroLegacy.new;let b;try{b=await F(e.ort,()=>(0,r.defaultModelFetcher)(y))}catch(re){throw console.error(`Encountered an error while loading model file ${y}`),re}const V=new a.FrameProcessor(b.process,b.reset_state,{frameSamples:u.frameSamples,positiveSpeechThreshold:u.positiveSpeechThreshold,negativeSpeechThreshold:u.negativeSpeechThreshold,redemptionFrames:u.redemptionFrames,preSpeechPadFrames:u.preSpeechPadFrames,minSpeechFrames:u.minSpeechFrames,submitUserSpeechOnPause:u.submitUserSpeechOnPause}),k=new v(p,u,V);return await k.setupAudioNode(),k}constructor(p,h,u){this.ctx=p,this.options=h,this.bufferIndex=0,this.pause=()=>{const l=this.frameProcessor.pause();this.handleFrameProcessorEvent(l)},this.start=()=>{this.frameProcessor.resume()},this.receive=l=>{l.connect(this.audioNode)},this.processFrame=async l=>{const y=await this.frameProcessor.process(l);this.handleFrameProcessorEvent(y)},this.handleFrameProcessorEvent=l=>{switch(l.probs!==void 0&&this.options.onFrameProcessed(l.probs,l.frame),l.msg){case i.Message.SpeechStart:this.options.onSpeechStart();break;case i.Message.VADMisfire:this.options.onVADMisfire();break;case i.Message.SpeechEnd:this.options.onSpeechEnd(l.audio);break}},this.destroy=()=>{this.audioNode instanceof AudioWorkletNode&&this.audioNode.port.postMessage({message:i.Message.SpeechStop}),this.audioNode.disconnect(),this.gainNode?.disconnect()},this.frameProcessor=u}async setupAudioNode(){if("audioWorklet"in this.ctx&&typeof AudioWorkletNode=="function")try{const l=this.options.baseAssetPath+O;await this.ctx.audioWorklet.addModule(l);const y=this.options.workletOptions??{};y.processorOptions={...y.processorOptions??{},frameSamples:this.options.frameSamples},this.audioNode=new AudioWorkletNode(this.ctx,"vad-helper-worklet",y),this.audioNode.port.onmessage=async F=>{switch(F.data?.message){case i.Message.AudioFrame:let b=F.data.data;b instanceof ArrayBuffer||(b=new ArrayBuffer(F.data.data.byteLength),new Uint8Array(b).set(new Uint8Array(F.data.data)));const V=new Float32Array(b);await this.processFrame(V);break}};return}catch(l){console.log("AudioWorklet setup failed, falling back to ScriptProcessor",l)}this.resampler=new m.Resampler({nativeSampleRate:this.ctx.sampleRate,targetSampleRate:16e3,targetFrameSize:this.options.frameSamples??480});const h=4096;this.audioNode=this.ctx.createScriptProcessor(h,1,1),this.gainNode=this.ctx.createGain(),this.gainNode.gain.value=0;let u=!1;this.audioNode.onaudioprocess=async l=>{if(!u){u=!0;try{const y=l.inputBuffer.getChannelData(0);if(l.outputBuffer.getChannelData(0).fill(0),this.resampler){const b=this.resampler.process(y);for(const V of b)await this.processFrame(V)}}catch(y){console.error("Error processing audio:",y)}finally{u=!1}}},this.audioNode.connect(this.gainNode),this.gainNode.connect(this.ctx.destination)}}e.AudioNodeVAD=v})(se);(function(e){var n=A&&A.__createBinding||(Object.create?function(S,g,_,v){v===void 0&&(v=_);var f=Object.getOwnPropertyDescriptor(g,_);(!f||("get"in f?!g.__esModule:f.writable||f.configurable))&&(f={enumerable:!0,get:function(){return g[_]}}),Object.defineProperty(S,v,f)}:function(S,g,_,v){v===void 0&&(v=_),S[v]=g[_]}),o=A&&A.__setModuleDefault||(Object.create?function(S,g){Object.defineProperty(S,"default",{enumerable:!0,value:g})}:function(S,g){S.default=g}),t=A&&A.__importStar||function(S){if(S&&S.__esModule)return S;var g={};if(S!=null)for(var _ in S)_!=="default"&&Object.prototype.hasOwnProperty.call(S,_)&&n(g,S,_);return o(g,S),g};Object.defineProperty(e,"__esModule",{value:!0}),e.NonRealTimeVAD=e.Message=e.FrameProcessor=e.getDefaultRealTimeVADOptions=e.MicVAD=e.DEFAULT_MODEL=e.AudioNodeVAD=e.utils=e.defaultNonRealTimeVADOptions=void 0;const s=t(J),r=L,a=N,c=w;Object.defineProperty(e,"FrameProcessor",{enumerable:!0,get:function(){return c.FrameProcessor}});const i=M;Object.defineProperty(e,"Message",{enumerable:!0,get:function(){return i.Message}});const d=Q,m=P;e.defaultNonRealTimeVADOptions={modelURL:r.baseAssetPath+"silero_vad_legacy.onnx",modelFetcher:a.defaultModelFetcher};class O extends d.PlatformAgnosticNonRealTimeVAD{static async new(g={}){const{modelURL:_,modelFetcher:v}={...e.defaultNonRealTimeVADOptions,...g};return await this._new(()=>v(_),s,g)}}e.NonRealTimeVAD=O,e.utils={audioFileToArray:m.audioFileToArray,minFramesForTargetMS:m.minFramesForTargetMS,arrayBufferToBase64:m.arrayBufferToBase64,encodeWAV:m.encodeWAV};var D=se;Object.defineProperty(e,"AudioNodeVAD",{enumerable:!0,get:function(){return D.AudioNodeVAD}}),Object.defineProperty(e,"DEFAULT_MODEL",{enumerable:!0,get:function(){return D.DEFAULT_MODEL}}),Object.defineProperty(e,"MicVAD",{enumerable:!0,get:function(){return D.MicVAD}}),Object.defineProperty(e,"getDefaultRealTimeVADOptions",{enumerable:!0,get:function(){return D.getDefaultRealTimeVADOptions}})})(W);const ve=oe(W),Fe=ne({__proto__:null,default:ve},[W]);export{Fe as i};
